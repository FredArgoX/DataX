<h1 class="code-title">Support Vector Machine <span class="blue">(</span>SVM<span class="blue">)</span></h1>
<p class="ml-type-1">Supervised Learning</p>
<p class="ml-type-2">Classification</p>
<p class="code-concept">Support vector machines (SVMs) are a set of supervised learning methods used for classification and regression.</p>
<p class="code-concept"><span class="blue">The method used for classification is called Support Vector Classification (SVC).</span></p>
<p class="code-concept">SVC is inherently a binary classifier. It can handle multi-class classification by using strategies like One-vs-One (OvO) and One-vs-All (OvA). If desired, OvO or OvA can be implemented manually, but if not explicitly implemented, Scikit-Learn automatically handles it.</p>
<p class="code-concept">SVC works by finding the optimal hyperplane, also known as <span class="blue">MMH</span> (Maximum Marginal Hyperplane), that best separates different classes in the dataset. The optimal hyperplane (decision boundary) maximizes the <span class="blue">margin</span> between different classes in the dataset. The margin is the distance between the hyperplane and the nearest data points from each class, which are called <span class="blue">support vectors</span>. These support vectors are critical because they define the position and orientation of the hyperplane.</p>
<p class="code-concept">The hyperplane in 2D is a line, in 3D is a plane, and so on in higher dimensions. Some problems canâ€™t be solved using a linear hyperplane. In such situations, SVC uses a <span class="blue">kernel trick</span> to transform the input space into a higher-dimensional space.</p>
<p class="code-concept">SVC works naturally with numerical data since the algorithm depends on distance calculations between data points. Therefore, <span class="blue">categorical data must be transformed into numerical representations</span>.</p>
<p class="code-concept"><span class="blue">Feature scaling is crucial for SVC</span> because the algorithm is sensitive to the scale of the input features. Scaling ensures that features contribute equally, leading to a more meaningful decision boundary.</p>
<div class="just-code">
    <!--///////////////////-->
    <button class="copy-btn">
        <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="#1D4ED8" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon">
            <rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect>
            <path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path>
        </svg>
    </button>
    <!--///////////////////-->
    <pre><code class="language-python" id="SupVecMach-code"></code></pre>
</div>
<h1 class="code-example" id="SupVecMach-project">View Example Project</h1>